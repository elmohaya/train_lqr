JAX CUDA INSTALLATION TROUBLESHOOTING
======================================

STEP 1: Check CUDA Installation
--------------------------------
Run these commands on your server:

nvidia-smi
nvcc --version

If nvcc is not found, check:
ls /usr/local/cuda*/bin/nvcc

If found, add to PATH:
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH


STEP 2: Check Current JAX Installation
---------------------------------------
python3 -c "import jax; print(jax.__version__); print(jax.devices())"
pip3 show jaxlib | grep Version


STEP 3: Complete Uninstall and Reinstall
-----------------------------------------
# Uninstall everything JAX-related
pip3 uninstall -y jax jaxlib flax optax

# Clear pip cache
pip3 cache purge

# For CUDA 11.8 (common on servers with RTX 2080 Ti):
pip3 install --upgrade pip
pip3 install "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# OR for CUDA 12.x:
pip3 install "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# Install other dependencies
pip3 install flax optax


STEP 4: If Still Not Working - Manual Installation
---------------------------------------------------
Check your CUDA version exactly:
cat /usr/local/cuda/version.txt
# OR
ls -l /usr/local | grep cuda

Then install matching JAX version:

# For CUDA 11.8:
pip3 install jax==0.4.20 jaxlib==0.4.20+cuda11.cudnn86 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# For CUDA 12.0:
pip3 install jax==0.4.20 jaxlib==0.4.20+cuda12.cudnn89 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html


STEP 5: Set Environment Variables
----------------------------------
Add these to your ~/.bashrc:

echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
echo 'export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/cuda' >> ~/.bashrc
source ~/.bashrc


STEP 6: Verify Again
--------------------
python3 << EOF
import jax
print("JAX version:", jax.__version__)
print("Devices:", jax.devices())
print("Device count:", jax.device_count())

# Try a simple computation
if jax.device_count() > 0:
    import jax.numpy as jnp
    x = jnp.ones(10)
    y = x + 1
    print("Simple computation works!")
    print("Device used:", x.device())
EOF


STEP 7: Alternative - Use PyTorch Instead
------------------------------------------
If JAX continues to have issues, you can use the PyTorch version:

# On server:
pip3 install torch torchvision torchaudio

# Then use train_fast.py instead of train_jax.py:
python3 train_fast.py

PyTorch typically has better CUDA compatibility and will work with your
3x RTX 2080 Ti GPUs without issues.


STEP 8: Check CUDA Compatibility
---------------------------------
JAX requires:
- CUDA 11.8 or 12.x
- cuDNN 8.6+ (for CUDA 11) or 8.9+ (for CUDA 12)
- NVIDIA driver >= 450.80.02

Check your driver:
cat /proc/driver/nvidia/version

If driver is old, JAX won't work. In this case, use PyTorch (train_fast.py).


QUICK FIX: Use PyTorch (Recommended)
=====================================
PyTorch is more stable and easier to setup:

1. Install PyTorch:
   pip3 install torch torchvision torchaudio

2. Train using PyTorch:
   python3 train_fast.py

3. Test using PyTorch:
   python3 train.py  # (will need to create test_pytorch.py)

PyTorch will automatically detect and use all 3 GPUs with DataParallel,
and you'll get similar performance to JAX.


EXPECTED TIMELINE:
==================
- JAX troubleshooting: 30-60 minutes
- PyTorch setup: 5 minutes

For immediate results, I recommend using PyTorch (train_fast.py).
It's production-ready and will work immediately with your hardware.

